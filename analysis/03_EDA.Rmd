---
title: "Exploratory Data Analysis"
output: html_document
---

```{r global_options, include=FALSE}
source(here::here("code", "01_packages.R"))
source(here::here("code/02_knitr-global.R"))
```

## Initial observations


The current status of the working file with the fesshole data is

```{r}
# Read in rds file if required
fesshole_new <- read_rds(here::here("data", "fesshole_new.rds"))
```

```{r}
fesshole_new %>% 
  glimpse()
```

The number of rows my differ upon updates done to the file.

One of the first observations we can make is the number of words in each confession.  That way we
can identify the longest confession, and when it was submitted.

### The longest confession?

Which one is the longest confession to date.

We can add a word count column that can estimate the number of words per confession using the
`stringr::str_count()` function.

We use `[\\w\']+` to identify words with apostrophes taking into account the number of letters 
after the aposotrophy ([see here for reference.](https://stackoverflow.com/questions/8920145/count-the-number-of-all-words-in-a-string) )

```{r}
# Add a column with word counts
fesshole_new %>% 
  mutate(wordcount_est = stringr::str_count(confessions, '[\\w\']+')) %>% 
  sample_n(5)
  
```


Now let's find out the entry with the maximumn number of words

```{r}
fesshole_new %>% 
  mutate(wordcount_est = stringr::str_count(confessions, '[\\w\']+')) %>% 
  slice(which.max(wordcount_est)) %>% 
  pull()
```

And when this entry was submitted...


```{r}
fesshole_new %>% 
  mutate(wordcount_est = stringr::str_count(confessions, '[\\w\']+')) %>% 
  slice(which.max(wordcount_est)) %>% 
  select(timestamp) %>% 
  pull()

```

It was submitted on `r fesshole_new %>% mutate(wordcount_est = stringr::str_count(confessions, '[\\w\']+')) %>% slice(which.max(wordcount_est)) %>% select(timestamp) %>% pull()`

Here's the text of the longest confession: a very juicy account of identity theft, gay politicians, lots of alcohol and the Brexit.

```{r}
fesshole_new %>% 
  mutate(wordcount = stringr::str_count(confessions, '[\\w\']+')) %>% 
  slice(which.max(wordcount)) %>% 
  select(confessions) %>% 
  pull()

```

Oh wow. This is a very juicy account of identity theft, gay politicians, lots of alcohol and the Brexit.

The paragraph contains line breaks `\n` that somehow made it into the calculation of the number of words.
That is why the number of words is marked as estimate.

These are the top 10 longest confessions.

```{r}
fesshole_new %>% 
  mutate(wordcount = stringr::str_count(confessions, '[\\w\']+')) %>% 
  arrange(desc(wordcount)) %>% 
  head(10)
```

## Indexing the dataset

We will index every confession.  This will help us track the words and associate them to the confession
they belong.

This will create a new data frame that we will save for future reference in our analysis.

```{r}
# Add index column called confess_id
fesshole_index <- fesshole_new %>% 
  mutate(confess_id = row_number()) %>% 
  relocate(confess_id)

# Check the index number of the first 6 (head) and last 6 (tail) entries
fesshole_index %>% 
  head()

fesshole_index %>% 
  tail()

# Comment out when an update is required.  Comment back in when done  
# write_rds(fesshole_index, here::here("data", "fesshole_index.rds"))
```


Removing stopwords from the pairs of words

```{r}
fesshole_pairs_xl <- read_rds(here::here("data", "fesshole_pairs_xl.rds"))
fesshole_pairs_xl %>% 
  count(pairs, word1, word2, sort = TRUE) %>% 
   filter(!word1 %in% tidytext::stop_words$word) %>%
  filter(!word2 %in% tidytext::stop_words$word)
  
  
```






