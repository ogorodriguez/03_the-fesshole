---
title: "The Fesshole Spreadsheet"
output: html_document
---

```{r global_options, include=FALSE}
source(here::here("code", "01_packages.R"))
source(here::here("code/02_knitr-global.R"))
```

## The Fesshole Spreadsheet

[The Fesshole Spreadsheet](https://docs.google.com/spreadsheets/d/1wiUl3SiU6qlRU50WN1sKZ0ERXXj_7WVvF5QFxTMTAaY/edit#gid=1599891978) is a live document collecting all confession sent by any person
who has access to the form.  That way, confessions can arrive at any given moment any day any time.  
Confessions are all in English since its origin is a twitter account managed presumably from the UK, I believe.

It consists of mainly two columns.  A third column host basic information about the spreadsheet 
on the first three rows.  The first and second columns are the ones with the timestamp and
the text of the confession respectively.

!["Example of The Fesshole Google Spreadsheet"](assets/01_fesshole-spread.png)

## Importing the Fesshole Spreadsheet

To import it to become part of the analysis we will need to do some rearranging during import.

First we will import the raw spreadsheet as is using the `googlesheets4::read_sheet()` function.  
Authentication to google drive may be required.

The next steps will be commented out to keep the operations as minimum.  An RDS version of the
file will be downloaded and used for analysis.  We can check creation time and modification time
if needed to see if an update is required.

I suggest updating the file if a minimum of 15 days have elapsed since tis creation.

```{r, message = FALSE}
# Run this if an updated version of the spreadsheet is needed for analysis
# Save file as RDS in project folder
# Un-comment to update and comment back again
# fesshole_raw <- googlesheets4::read_sheet("https://docs.google.com/spreadsheets/d/1wiUl3SiU6qlRU50WN1sKZ0ERXXj_7WVvF5QFxTMTAaY/edit#gid=1599891978", col_types = "c"  )

```

```{r}
# Saving raw spreadsheet as rds
# Un-comment when updating spreadsheet 
# Comment back again when saving new updated raw RDS file
# write_rds(fesshole_raw, here::here("data", "data_raw", "fesshole_raw.rds"))

```

Let's check the creation time of the fesshole_raw rds file.

```{r}
rds_created <- file.info(here::here("data", "data_raw", "fesshole_raw.rds"))$ctime
rds_created
```

How many days have elapsed since file creation?

```{r}
round(Sys.time() - rds_created, 0)
```

If the difference is 15 days or more, please update and save as RDS the fesshole_raw filw following the indications above.

## Revising the raw file

For the revision we will read the RDS file of the fesshole spreadsheet.

```{r}
fesshole_rds <- read_rds(here::here("data", "data_raw", "fesshole_raw.rds"))
```

Let's preview it

```{r}
fesshole_rds %>% 
  head()
```
As indicated previously, the third column shows only general information regarding the confessions and
can be safely removed.  

During the import the column type selected was character thus affecting the timestamp column.  
Timestamp will be reverted back to data using the lubridate function.

We will rename the remaining columns to simplified the variables names and make them consistent.


```{r}
fesshole_new <- fesshole_rds %>% 
  select(Timestamp, `What's your confession?`) %>% 
  rename(confessions = `What's your confession?`,
         timestamp = Timestamp) %>% 
  mutate(timestamp = lubridate::mdy_hms(timestamp))

```

We will visualize a random selection of 5 rows from the data.

```{r}
fesshole_new %>%
  dplyr::sample_n(5)
```

This did not require much data wrangling it seems.  We will save it as an rds version.  
This will be commented out and only needs to be reactivated when updating fesshole_raw.

```{r}
# write_rds(fesshole_new, here::here("data", "fesshole_new.rds"))
```


## Indexing the dataset

We will index every confession.  This will help us track the words and associate them to the confession
they belong.

This will create a new data frame that we will save for future reference in our analysis.

```{r}
# Add index column called confess_id
fesshole_index <- fesshole_new %>% 
  mutate(confess_id = row_number()) %>% 
  relocate(confess_id)

# Check the index number of the first 6 (head) and last 6 (tail) entries
fesshole_index %>% 
  head()

fesshole_index %>% 
  tail()

# Comment out when an update is required.  Comment back in when done  
# write_rds(fesshole_index, here::here("data", "fesshole_index.rds"))
```


## Getting more details: Year, Month, Day and Time  

Another data set to have is one where the date is separated into colunms so we can see month, day, day of week, year, and event the time separartely.  This may help answer questions such as which time is most common for 
people to submit confessions.   As well as which month are most or least popular for example.

40,000+ confession have been submitted since July 2019 until Dec 2020, which is relatively a small time compared to the number of entries already in the dataset.  This may not actually be so representative perhaps, but it could help derive some predictions into the future who knows.

```{r}
fesshole_detailed <- fesshole_index %>% 
  mutate(year = lubridate::year(timestamp),
         month = lubridate::month(timestamp, label = TRUE, abbr = FALSE),
         day_label = lubridate::wday(timestamp, label = TRUE, abbr = FALSE),
         day = lubridate::day(timestamp)
         )

fesshole_detailed %>% 
  sample_n(5)

# Comment out when an update is required.  Comment back in when done  
# write_rds(fesshole_detailed, here::here("data", "fesshole_detailed.rds"))

```


## Gettting the corpus of the Confessions

Another data set to create is the one with each word from all the confessions.  This will drive
the text analysis and sentimental analysis of the spreadsheet.

I will keep the stop words and use the tf-idf to find relevance of words according to their frequency or rank.
[It is somehow recommended](https://datascience.stackexchange.com/questions/31048/pros-cons-of-stop-word-removal) not to remove stop words when doing sentiment analysis since stop words can
provide context that can be helpful.  The drawback will be the dimension of the data set may impact the analysis.

I will also use tokens to have a data set of pairs of words as well.  I will look into the size of the 
dataset in case it may harm future computations.

### Confession words

The confession words data set we will call `fesshole_words` will have each word per row and will
thus consider then as single units.  

```{r}
fesshole_words <- fesshole_index %>% 
  tidytext::unnest_tokens(word, confessions)

fesshole_words %>% 
  glimpse()

fesshole_words %>% 
  head(10)

# Comment out when an update is required.  Comment back in when done  
# write_rds(fesshole_words, here::here("data", "fesshole_words.rds"))

```


## Confession word pairs

The word pairs confessions data set will use the bigrams tool in the pakcage `tidytext`.  

This will help us see the relationship between words and will make sentiment analysis more pertinent
by identifying negation that comes from the use of words with negative connotation together with 
other words that may have a positive one.

This will also increase the volume of our dataset considerably due to duplication of terms to form the pairs.

```{r}
fesshole_pairs <- fesshole_index %>% 
  tidytext::unnest_tokens(bigrams, confessions, token = "ngrams", n = 2)
  
fesshole_pairs %>% 
  glimpse()

fesshole_pairs %>% 
  head(10)

# Comment out when an update is required.  Comment back in when done  
# write_rds(fesshole_pairs, here::here("data", "fesshole_pairs.rds"))

```

I will enhance the word pairs data set to include the words separate as well

```{r}
fesshole_pairs_xl <- fesshole_pairs %>% 
  mutate(pairs = bigrams) %>% 
  separate(bigrams, c("word1", "word2"), sep = " ")

fesshole_pairs_xl


# Comment out when an update is required.  Comment back in when done  
# write_rds(fesshole_pairs_xl, here::here("data", "fesshole_pairs_xl.rds"))
```




























